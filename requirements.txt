# Phi-3 Fine-tuning Requirements
# Optimized for 16GB GPU with QLoRA and memory efficiency

# Core ML Libraries
torch>=2.1.0
torchvision>=0.16.0
torchaudio>=2.1.0

# Transformers and Model Libraries
transformers>=4.36.0
tokenizers>=0.15.0
accelerate>=0.25.0
peft>=0.7.0  # For LoRA/QLoRA
bitsandbytes>=0.41.0  # For 4-bit quantization

# Training and Optimization
datasets>=2.15.0
trl>=0.7.0  # Transformer Reinforcement Learning
evaluate>=0.4.0
scikit-learn>=1.3.0

# Data Processing
pandas>=2.1.0
numpy>=1.24.0
openpyxl>=3.1.0  # For Excel files
xlrd>=2.0.0  # For older Excel formats

# Environment Management
python-dotenv>=1.0.0  # For .env file support

# Visualization and Monitoring
matplotlib>=3.7.0
seaborn>=0.12.0
wandb>=0.16.0  # For experiment tracking
tensorboard>=2.15.0

# Text Processing
nltk>=3.8.0
spacy>=3.7.0
regex>=2023.10.0

# Utilities
tqdm>=4.66.0
click>=8.1.0
python-dotenv>=1.0.0
pyyaml>=6.0.0
jsonlines>=4.0.0

# Jupyter and Development
jupyter>=1.0.0
notebook>=7.0.0
ipywidgets>=8.1.0

# Memory and Performance Monitoring
psutil>=5.9.0
py3nvml>=0.2.0  # For GPU monitoring
gpustat>=1.1.0

# API and Web
requests>=2.31.0
fastapi>=0.104.0  # For model serving
uvicorn>=0.24.0

# Testing and Quality
pytest>=7.4.0
black>=23.10.0
flake8>=6.1.0
mypy>=1.7.0